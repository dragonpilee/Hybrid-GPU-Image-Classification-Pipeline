
# ğŸš€ Hybrid GPU Image Classification Pipeline  
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![FastAI](https://img.shields.io/badge/FastAI-181717?style=for-the-badge&logo=fastapi&logoColor=white)
![CUDA](https://img.shields.io/badge/NVIDIA-CUDA-76B900?style=for-the-badge&logo=nvidia&logoColor=white)
![License: MIT](https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge)

> âš¡ A high-performance deep learning pipeline combining PyTorch, FastAI, CuPy, and Numba â€” **optimized for NVIDIA RTX GPUs** â€” to preprocess and train on the CIFAR-10 dataset with maximum GPU acceleration.

---

## ğŸ§  Overview

This repository demonstrates a **hybrid GPU pipeline** that offloads **image preprocessing** and **augmentation** to the GPU using:

- ğŸ§® **CuPy**: Fast NumPy-like GPU array computations  
- ğŸ”¬ **Numba**: Custom CUDA kernels for image brightness enhancement  
- ğŸ **FastAI**: Rapid model training using PyTorch under the hood  
- ğŸ® **RTX GPU Optimized**: Designed to fully leverage your RTX GPU (20xx, 30xx, or 40xx series)

---

## ğŸ“Š Demo Output

```bash
ğŸš€ Starting Hybrid GPU Image Classification Pipeline
Using device: cuda
Dataset loaded with batch size 128
Preprocessing sample batch with GPU kernels...
Starting training...
âœ… FastAI training completed
â±ï¸ Time: 18.53 sec
```

---

## ğŸ—ï¸ Pipeline Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CIFAR-10 Dataset   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
   FastAI DataLoaders
          â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ GPU Preprocessing Steps    â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ 1. CuPy Normalization       â”‚
  â”‚ 2. Numba Brightness Kernel  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
   FastAI ResNet-18 Model
          â†“
       Training Loop
```

---

## âš™ï¸ Installation

### âœ… Prerequisites

- NVIDIA **RTX GPU** with CUDA support  
- Python 3.8+  
- CUDA drivers installed and working  
- CUDA-compatible versions of PyTorch and CuPy

### ğŸ“¦ Install Dependencies

```bash
# For CUDA 11.8 and RTX GPUs
pip install cupy-cuda118

# Core packages
pip install torch torchvision fastai numba
```

> ğŸ’¡ Choose the CuPy version that matches your installed CUDA toolkit:  
> See the [CuPy install matrix](https://docs.cupy.dev/en/stable/install.html#using-pip).

---

## ğŸ§ª How to Run

```bash
https://github.com/dragonpilee/Hybrid-GPU-Image-Classification-Pipeline.git
cd hybrid-gpu-classifier
python train.py
```

---

## ğŸ” Code Highlights

### ğŸ”§ `gpu_normalize_images()`

Normalizes RGB image tensors using CuPy directly on GPU memory.

### ğŸ’¡ `brightness_kernel` (Numba)

Custom CUDA kernel that increases brightness pixel-wise on the GPU.

### ğŸ§¼ `preprocess_batch()`

Combines GPU normalization and augmentation, then converts back to PyTorch tensors.

### ğŸ§  `train_model()`

Initializes FastAIâ€™s ResNet-18 model and performs training with one-cycle policy.

---

## âš¡ Performance Tips

| Setting                     | Recommendation                     |
|----------------------------|-------------------------------------|
| GPU                        | NVIDIA RTX 2060/3060/4090 or higher |
| Batch Size                 | 128â€“256 for optimal GPU utilization |
| Data Preprocessing         | CuPy + Numba (already integrated)   |
| Precision                  | Add mixed precision for even faster training |
| Memory Management          | Use `.half()` and `torch.cuda.amp` for FP16 |

---

## ğŸš€ Future Improvements

- ğŸ” Integrate GPU-accelerated preprocessing inside FastAIâ€™s transform pipeline  
- ğŸ¨ Add more augmentation types (contrast, noise, rotation) via custom CUDA kernels  
- ğŸ“ˆ Benchmark performance across different GPUs (RTX 2060 vs 4090)  
- ğŸ’¾ Add model saving, evaluation, and inference scripts  

---

## ğŸ“œ License

This project is licensed under the **MIT License**.  
Feel free to fork, modify, and use it in your own projects.

---

## ğŸ‘¨â€ğŸ’» Author

**Alan Cyril Sunny**  
ğŸ“§ alan_cyril@yahoo.com  
ğŸ™ [GitHub](https://github.com/dragonpilee)

---

## ğŸŒŸ Show Your Support

If you found this useful, consider starring â­ the repo or sharing it with others!
